{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59cab0a5-7a28-40ed-a223-ee4d207d102a",
   "metadata": {},
   "source": [
    "# ReAct tool Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b66ef989-d44b-4652-a2fc-3e7e68c43951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence, TypedDict\n",
    "from dotenv import load_dotenv  \n",
    "from langchain_core.messages import BaseMessage # The foundational class for all message types in LangGraph\n",
    "from langchain_core.messages import ToolMessage # Passes data back to LLM after it calls a tool such as the content and the tool_call_id\n",
    "from langchain_core.messages import SystemMessage # Message for providing instructions to the LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e367f8a-0c27-4c61-b4f8-1f070e2bd547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2113665-30da-41b3-8f3a-0a48dbe5ef70",
   "metadata": {},
   "source": [
    "# Define the state (provide input to agent)\n",
    "Message is datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87823c8c-8b29-46f1-9ee1-e1bd5fed6fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b57e43-a56a-4032-8358-1425a56d9d93",
   "metadata": {},
   "source": [
    "# Create a tools\n",
    "# the comments below for each tool like instruct to tools what needd to be done , LLM model understand this and call the related tool do perform the actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "207cb855-de8f-494d-9dbe-7055ca8f51d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(a: int, b:int):\n",
    "    \"\"\"This is an addition function that adds 2 numbers together\"\"\"\n",
    "    return a + b \n",
    "\n",
    "@tool\n",
    "def subtract(a: int, b: int):\n",
    "    \"\"\"Subtraction function\"\"\"\n",
    "    return a - b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int):\n",
    "    \"\"\"Multiplication function\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269bb4ef-24eb-4514-9981-97a98f9b932a",
   "metadata": {},
   "source": [
    "# Add tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bd84f60-9b1b-46fd-8b91-218cae5a24ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [add, subtract, multiply]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f8238b-e69b-473d-9983-934cab774df7",
   "metadata": {},
   "source": [
    "# Bind the tools into chat models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dcf9123-da35-4764-8928-8713f99faaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model = \"gpt-4o\").bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b7f4a6-633d-4196-a2c5-a9ef728df3ee",
   "metadata": {},
   "source": [
    "# Create the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "746c053e-664b-4322-89c1-e993fbc580ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_call(state:AgentState) -> AgentState:\n",
    "    system_prompt = SystemMessage(content=\n",
    "        \"You are my AI assistant, please answer my query to the best of your ability.\"\n",
    "    )\n",
    "    response = model.invoke([system_prompt] + state[\"messages\"]) #  state[\"messages\" -> is input from user\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29c52362-3b6a-4a5e-9712-3465639ff720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: AgentState): \n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if not last_message.tool_calls: \n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13159298-80b4-4519-8b20-c3fb18462603",
   "metadata": {},
   "source": [
    "# Add node to stateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acb3cc75-c661-40b0-86fb-857b6e8fabc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x200db83a720>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"our_agent\", model_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91bf21a-6f49-49d1-a7cf-47ae4bd3f530",
   "metadata": {},
   "source": [
    "# Add tool nodes to stateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "196fce86-581d-4623-959f-14478e39025a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x200db83a720>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_node = ToolNode(tools=tools)\n",
    "graph.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be04419c-2c8e-4c46-bad6-2dca1f5f590b",
   "metadata": {},
   "source": [
    "# Set Entry & Exit point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69b98ae1-b915-47ab-852c-cc033286c1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x200db83a720>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.set_entry_point(\"our_agent\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"our_agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"tools\", # tools node call\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_edge(\"tools\", \"our_agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fbb5d66-4c5c-4ae3-8a61-13b502bc690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47fa0c03-bfca-4b3d-8181-14ca18fd3e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c412aac-5993-4c83-892a-6cc610c5d6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 40 + 12 and then multiply the result by 6. Also tell me a joke please.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_N0okHwrTYsc6Doe3vLgnmIcQ)\n",
      " Call ID: call_N0okHwrTYsc6Doe3vLgnmIcQ\n",
      "  Args:\n",
      "    a: 40\n",
      "    b: 12\n",
      "  multiply (call_siGD3MyuV5zA8gWaWzJnOVHe)\n",
      " Call ID: call_siGD3MyuV5zA8gWaWzJnOVHe\n",
      "  Args:\n",
      "    a: 52\n",
      "    b: 6\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "312\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 40 and 12 is 52, and multiplying that result by 6 gives 312.\n",
      "\n",
      "And here's a joke for you:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": [(\"user\", \"Add 40 + 12 and then multiply the result by 6. Also tell me a joke please.\")]}\n",
    "print_stream(app.stream(inputs, stream_mode=\"values\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852c1fd9-4a39-44e6-b8c2-b7f765485ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
